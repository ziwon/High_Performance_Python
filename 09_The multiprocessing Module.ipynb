{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "Here are some typical jobs for the multiprocessing module:\n",
    "- Parallelize a CPU-bound task with Process or Pool objects.\n",
    "- Parallelize an I/O-bound task in a Pool with threads using the (oddly named) dummy module.\n",
    "- Share pickled work via a Queue .\n",
    "- Share state between parallelized workers, including bytes, primitive datatypes, dictionaries, and lists."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "By using processes we run a number of Python interpreters in parallel, each with a private memory space with its own GIL, and each runs in series"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "Main componets of the multiprocessing module\n",
    "- **Process** - A forked copy of the current process; this creates a new process identifier and the task runs as an independent child process in the operating system. You can start and query the state of the Process and provide it with a target method to run.\n",
    "- **Pool** - Wraps the Process or threading.Thread API into a convenient pool of workers that share a chunk of work and return an aggregated result.\n",
    "- **Queue** - A FIFO queue allowing multiple producers and consumers.\n",
    "- **Pipe** - A uni- or bidirectional communication channel between two processes.\n",
    "- **Manager** - A high-level managed interface to share Python objects between processes.\n",
    "- **ctypes** - Allows sharing of primitive datatypes (e.g., integers, floats, and bytes) between processes after they have forked.\n",
    "- **Synchronization primitives** - Locks and semaphores to synchronize control flow between processe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Estimating Pi Using Processes and Threads"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Making 2500000.0 samples per worker\n",
      "Took 1.5402233600616455s\n",
      "Estimated pi 3.141894\n",
      "Pi 3.141592653589793\n"
     ]
    }
   ],
   "source": [
    "\"\"\"Estimate Pi using blocks of serial work on 1 CPU\"\"\"\n",
    "import time\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "def estimate_nbr_points_in_circle(nbr_samples):\n",
    "    # set random seed for numpy in each new process\n",
    "    # else the fork will mean they all share the same state\n",
    "    np.random.seed()\n",
    "    xs = np.random.uniform(0, 1, int(nbr_samples))\n",
    "    ys = np.random.uniform(0, 1, int(nbr_samples))\n",
    "    estimate_inside_quarter_unit_circle = (xs * xs + ys * ys) <= 1\n",
    "    nbr_trials_in_quarter_unit_circle = np.sum(\n",
    "        estimate_inside_quarter_unit_circle)\n",
    "    return nbr_trials_in_quarter_unit_circle\n",
    "\n",
    "\n",
    "nbr_samples_in_total = 1e7 # le8 causes memory error in the later example\n",
    "\n",
    "nbr_parallel_blocks = 4\n",
    "nbr_samples_per_worker = nbr_samples_in_total / nbr_parallel_blocks\n",
    "print(\"Making {} samples per worker\".format(nbr_samples_per_worker))\n",
    "\n",
    "t1 = time.time()\n",
    "nbr_in_circle = 0\n",
    "for npb in range(nbr_parallel_blocks):\n",
    "    nbr_in_circle += estimate_nbr_points_in_circle(nbr_samples_per_worker)\n",
    "print(\"Took {}s\".format(time.time() - t1))\n",
    "pi_estimate = float(nbr_in_circle) / nbr_samples_in_total * 4\n",
    "print(\"Estimated pi\", pi_estimate)\n",
    "print(\"Pi\", np.pi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Making 2500000.0 samples per worker\n",
      "Dart throws in unit circle per worker: [1963029, 1964054, 1963190, 1962623]\n",
      "Took 1.0072505474090576\n",
      "Estimated pi 3.1411584\n",
      "Pi 3.141592653589793\n"
     ]
    }
   ],
   "source": [
    "from multiprocessing import Pool\n",
    "\n",
    "def estimate_nbr_points_in_quarter_circle(nbr_samples):\n",
    "    np.random.seed()\n",
    "    xs = np.random.uniform(0, 1, int(nbr_samples))\n",
    "    ys = np.random.uniform(0, 1, int(nbr_samples))\n",
    "    estimate_inside_quarter_unit_circle = (xs * xs + ys * ys) <= 1\n",
    "    nbr_trials_in_quarter_unit_circle = np.sum(\n",
    "        estimate_inside_quarter_unit_circle)\n",
    "    return nbr_trials_in_quarter_unit_circle\n",
    "\n",
    "nbr_samples_in_total = 1e7 # 1e8 causes memory error \n",
    "nbr_parallel_blocks = 4\n",
    "\n",
    "pool = Pool()\n",
    "\n",
    "nbr_samples_per_worker = nbr_samples_in_total / nbr_parallel_blocks\n",
    "print(\"Making {} samples per worker\".format(nbr_samples_per_worker))\n",
    "\n",
    "# confirm we have an integer number of jobs to distribute\n",
    "assert nbr_samples_per_worker == int(nbr_samples_per_worker)\n",
    "nbr_samples_per_worker == int(nbr_samples_per_worker)\n",
    "map_inputs = [nbr_samples_per_worker] * nbr_parallel_blocks\n",
    "t1 = time.time()\n",
    "results = pool.map(estimate_nbr_points_in_quarter_circle, map_inputs)\n",
    "pool.close()\n",
    "print(\"Dart throws in unit circle per worker:\", results)\n",
    "print(\"Took {}\".format(time.time() - t1))\n",
    "nbr_in_circle = sum(results)\n",
    "combined_nbr_samples = sum(map_inputs)\n",
    "\n",
    "pi_estimate = float(nbr_in_circle) / combined_nbr_samples * 4\n",
    "print(\"Estimated pi\", pi_estimate)\n",
    "print(\"Pi\", np.pi)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### GIL Battle\n",
    "David Beazley explains GIL Battle in [\"Understanding the Python GIL.\"](http://www.dabeaz.com/GIL/) \n",
    "- Threads in Python are great for I/O-bound tasks, \n",
    "- but they’re a poor choice for CPU-bound problems.\n",
    "- a single-core system with multiple threads has no “GIL battle.”\n",
    "- http://www.dabeaz.com/GIL/gilvis/fourthread.html \n",
    "<img src=\"http://apprize.info/python/high/high.files/image076.jpg\",width=400>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from threading import Thread\n",
    "import time\n",
    "\n",
    "def countdown(n):\n",
    "    while n > 0:\n",
    "        n -= 1\n",
    "\n",
    "COUNT = 10000000\n",
    "\n",
    "t1 = Thread(target=countdown,args=(COUNT/4,))\n",
    "t2 = Thread(target=countdown,args=(COUNT/4,))\n",
    "t3 = Thread(target=countdown,args=(COUNT/4,))\n",
    "t4 = Thread(target=countdown,args=(COUNT/4,))\n",
    "start = time.time()\n",
    "t1.start();t2.start(); t3.start(); t4.start()\n",
    "t1.join();t2.join(); t3.join(); t4.join()\n",
    "end = time.time()\n",
    "print (end-start)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
