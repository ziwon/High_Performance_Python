{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from math import sin\n",
    "\n",
    "def loop_slow(num_iterations):\n",
    "    result = 0\n",
    "    for i in xrange(num_iterations):\n",
    "        result += i * sin(num_iterations)\n",
    "    return result\n",
    "\n",
    "def loop_fast(num_iterations):\n",
    "    result = 0 \n",
    "    factor = sin(num_iterations)\n",
    "    for i in range(num_iterations):\n",
    "        result += i\n",
    "    return result * factor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%load_ext line_profiler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Pure Python 2D diffusion profiling\n",
    "from diffusion_python import run_experiment\n",
    "%lprun -f run_experiment run_experiment(500)\n",
    "\n",
    "'''\n",
    "Timer unit: 1e-06 s\n",
    "\n",
    "Total time: 178.527 s\n",
    "File: /home/luno/Workspace/high_performance_python/diffusion_python.py\n",
    "Function: run_experiment at line 23\n",
    "\n",
    "Line #      Hits         Time  Per Hit   % Time  Line Contents\n",
    "==============================================================\n",
    "    23                                           def run_experiment(num_iterations):\n",
    "    24                                               # setting up initial conditions\n",
    "    25         1            9      9.0      0.0      xmax, ymax = grid_shape\n",
    "    26         1           16     16.0      0.0      grid = [[0.0, ] * ymax] * xmax\n",
    "    27                                           \n",
    "    28                                               # initialization assumes that xmax <= ymax\n",
    "    29         1           14     14.0      0.0      block_low = int(xmax * .4)\n",
    "    30         1            4      4.0      0.0      block_high = int(xmax * .5)\n",
    "    31        53           86      1.6      0.0      for i in range(block_low, block_high):\n",
    "    32      2756         4013      1.5      0.0          for j in range(block_low, block_high):\n",
    "    33      2704         4066      1.5      0.0              grid[i][j] = 0.005\n",
    "    34                                           \n",
    "    35         1           15     15.0      0.0      start = time.time()\n",
    "    36       501         1027      2.0      0.0      for i in range(num_iterations):\n",
    "    37       500    178518229 357036.5    100.0          grid = evolve(grid, 0.1)\n",
    "    38         1            3      3.0      0.0      return time.time() - start\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Pure Python 2D diffusion after reducing memory allocation\n",
    "from diffusion_python_memory import run_experiment\n",
    "%lprun -f run_experiment run_experiment(500)\n",
    "\n",
    "'''\n",
    "Timer unit: 1e-06 s\n",
    "\n",
    "Total time: 171.316 s\n",
    "File: /home/luno/Workspace/high_performance_python/diffusion_python_memory.py\n",
    "Function: run_experiment at line 19\n",
    "\n",
    "Line #      Hits         Time  Per Hit   % Time  Line Contents\n",
    "==============================================================\n",
    "    19                                           def run_experiment(num_iterations):\n",
    "    20                                               # setting up initial conditions\n",
    "    21         1            6      6.0      0.0      xmax, ymax = grid_shape\n",
    "    22         1           10     10.0      0.0      grid = [[0.0, ] * ymax] * xmax\n",
    "    23         1           17     17.0      0.0      scratch = [[0.0, ] * ymax] * xmax\n",
    "    24                                           \n",
    "    25                                               # initialization assumes that xmax <= ymax\n",
    "    26         1           10     10.0      0.0      block_low = int(xmax * .4)\n",
    "    27         1            3      3.0      0.0      block_high = int(xmax * .5)\n",
    "    28        53           79      1.5      0.0      for i in range(block_low, block_high):\n",
    "    29      2756         5834      2.1      0.0          for j in range(block_low, block_high):\n",
    "    30      2704         4629      1.7      0.0              grid[i][j] = 0.005\n",
    "    31                                           \n",
    "    32         1            7      7.0      0.0      start = time.time()\n",
    "    33       501          284      0.6      0.0      for i in range(num_iterations):\n",
    "    34       500    171304020 342608.0    100.0          evolve(grid, 0.1, scratch)\n",
    "    35       500         1254      2.5      0.0          grid, scratch = scratch, grid\n",
    "    36         1            3      3.0      0.0      return time.time() - start\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Python lists store pointers: it stores data's location, not holding the data.\n",
    "# So there must be multiple lookups when fetching an element from `grid` matrix.\n",
    "\n",
    "# Memory fragmentation: The data located in one continuous block in memory, \n",
    "# we could move all of the data in one operation - this could occur memory fragmentation.\n",
    "# memory transfer overhead: such as `cache-misses`\n",
    "\n",
    "# https://hbfs.wordpress.com/2013/01/08/python-memory-management-part-ii/\n",
    "\n",
    "# But how do we know what data will be needed in the future?\n",
    "# => CPU's branch prediction and pipelining\n",
    "\n",
    "# Probing how well memory is being moved to the CPU can be quite hard\n",
    "# => Linux's `perf`\n",
    "\n",
    "# sudo apt-get install linux-tools-generic\n",
    "# sudo apt-get install linux-cloud-tools-generic"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "> perf stat -e cycles,stalled-cycles-frontend,stalled-cycles-backend,instructions,\\\n",
    "cache-references,cache-misses,branches,branch-misses,task-clock,faults,\\\n",
    "minor-faults,cs,migrations -r 3 python diffusion_python_memory.py\n",
    "\n",
    " Performance counter stats for 'python diffusion_python_memory.py' (3 runs):\n",
    "\n",
    "   228,108,155,330      cycles                    #    3.574 GHz                      ( +-  1.07% )\n",
    "   <not supported>      stalled-cycles-frontend\n",
    "   <not supported>      stalled-cycles-backend\n",
    "   663,731,493,774      instructions              #    2.91  insns per cycle          ( +-  0.00% )\n",
    "       176,306,169      cache-references          #    2.762 M/sec                    ( +- 17.48% )\n",
    "        93,035,988      cache-misses              #   52.770 % of all cache refs      ( +-  3.24% )\n",
    "   130,599,416,533      branches                  # 2045.993 M/sec                    ( +-  0.00% )\n",
    "       429,253,502      branch-misses             #    0.33% of all branches          ( +-  4.84% )\n",
    "      63831.814032      task-clock (msec)         #    0.996 CPUs utilized            ( +-  1.28% )\n",
    "               841      faults                    #    0.013 K/sec                    ( +-  0.04% )\n",
    "               841      minor-faults              #    0.013 K/sec                    ( +-  0.04% )\n",
    "             4,213      cs                        #    0.066 K/sec                    ( +- 66.20% )\n",
    "                 1      migrations                #    0.000 K/sec                    ( +-100.00% )\n",
    "\n",
    "      64.081283044 seconds time elapsed                                          ( +-  1.51% )\n",
    "```\n",
    "\n",
    "- `task-clock`: how many clock cycles our task took, the CPU utilization isn't exactly 1 because there were periods where the process relied on other subsystems to do instructions for it\n",
    "- `context-switches`: how the program is halted in order to wait for a kernel operation to finish.`CPU-migrations`: when the program is halted and resumed on a different CPU \n",
    "- `page-fault`: the modern Unix memory allocation scheme. when the memory is first used, the operating system throws a minor page fault interrupt, which pause the program that is being run and properly allocates the memory. (lazy allocation system). minor page faults: outside of the scope of the program, major page fault: when the program requests data from a device (disk, network, etc.) that hasn't been read yet.\n",
    "- `cache-reference`: whenever we reference the data that is in our cache, this increases. `cache-miss`: when we fetch data from RAM, counts as a `cache-miss` (CPU bound work)\n",
    "- `intructions`: how many instructions our code is issuing to the CPU. `insns per cycle`: Because of pipelining, these instructions can be run several at a time. `stalled-cycles-frontend` and `stalled-cycles-backed`: how many cycles our program was waiting for the frontend or backend of the pipeline to be filled. frontend: responsible for fetching the next instruction from memory and decoding it into a valid operation, backend: actually running the operation. Pipelining: run the current operation while fetching and preparing the next one.\n",
    "- `branch`: a time in the code where the execution flow changes (like if.. then). for optimizing this, the CPU tries to guess which direction the branch will take and preload the relevant instructions. we will get `stalled-cycles` and `branch-miss` when this prediction is in incorrect.\n",
    "- http://stackoverflow.com/questions/22712956/why-does-perf-stat-show-stalled-cycles-backend-as-not-supported\n",
    "- http://www.bnikolic.co.uk/blog/hpc-prof-events.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- L1/L2 cache 35,497,196 times\n",
    "- Of those of them, 10,716,972 (30.1%) were requests for data that wasn't in memory at the time\n",
    "- And an average of 1.82 instructions (total speed boost from pipelining, out-of-order execution, and hyperthreading)\n",
    "- Fragmentations prevent vectorizaion of computations (or having the CPU do multiple computations at a time) Since the bus can only move contiguous chunks of memory, this is only possible if the grid data is stored sequentially in RAM. But the actual values in Python lists in the grid are scattered througout memory and cannot be copied all at once."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- `array` module instead of lists, stores data sequentially in memory, so that a lice of the array actually represents a continuous range in memory.\n",
    "- But Python dosen't know how to vectorize our loops (no bytecode optimization in Python)\n",
    "- looping an `array` is slower than looping an `list`\n",
    "- not for math, more suitable for storing fixed-type data more efficiently in memory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from array import array\n",
    "import numpy\n",
    "\n",
    "def norm_square_list(vector):\n",
    "    norm = 0\n",
    "    for v in vector:\n",
    "        norm += v*v\n",
    "    return norm\n",
    "\n",
    "def norm_square_list_comprehension(vector):\n",
    "    return sum([v*v for v in vector])\n",
    "\n",
    "def norm_square_generator_comprehension(vector):\n",
    "    return sum([v*v for v in vector])\n",
    "\n",
    "def norm_square_array(vector):\n",
    "    norm = 0\n",
    "    for v in vector:\n",
    "        norm += v*v\n",
    "    return norm\n",
    "\n",
    "def norm_square_numpy(vector):\n",
    "    return numpy.sum(vector * vector)\n",
    "\n",
    "def norm_square_numpy_dot(vector):\n",
    "    return numpy.dot(vector, vector)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "vector = range(1000000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10 loops, best of 3: 63.1 ms per loop\n"
     ]
    }
   ],
   "source": [
    "%timeit norm_square_list(vector)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10 loops, best of 3: 62.1 ms per loop\n"
     ]
    }
   ],
   "source": [
    "%timeit norm_square_list_comprehension(vector)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10 loops, best of 3: 63.8 ms per loop\n"
     ]
    }
   ],
   "source": [
    "%timeit norm_square_generator_comprehension(vector)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "vector = array('l', range(1000000))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10 loops, best of 3: 61.3 ms per loop\n"
     ]
    }
   ],
   "source": [
    "%timeit norm_square_array(vector)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "vector = numpy.arange(1000000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100 loops, best of 3: 1.9 ms per loop\n"
     ]
    }
   ],
   "source": [
    "%timeit norm_square_numpy(vector)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000 loops, best of 3: 672 µs per loop\n"
     ]
    }
   ],
   "source": [
    "%timeit norm_square_numpy_dot(vector)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Numpy Naive Version\n",
    "from diffusion_numpy_naive import run_experiment\n",
    "%lprun -f run_experiment run_experiment(500)\n",
    "\n",
    "'''\n",
    "Timer unit: 1e-06 s\n",
    "\n",
    "Total time: 2.85241 s\n",
    "File: /home/luno/Workspace/high_performance_python/diffusion_numpy_naive.py\n",
    "Function: run_experiment at line 16\n",
    "\n",
    "Line #      Hits         Time  Per Hit   % Time  Line Contents\n",
    "==============================================================\n",
    "    16                                           def run_experiment(num_iterations):\n",
    "    17         1           10     10.0      0.0      grid = zeros(grid_shape)\n",
    "    18                                           \n",
    "    19         1            2      2.0      0.0      block_low = int(grid_shape[0] * .4)\n",
    "    20         1            1      1.0      0.0      block_high = int(grid_shape[0] * .5)\n",
    "    21         1           50     50.0      0.0      grid[block_low:block_high, block_low:block_high] = 0.005\n",
    "    22                                           \n",
    "    23         1            1      1.0      0.0      start = time.time()\n",
    "    24       501         1623      3.2      0.1      for i in range(num_iterations):\n",
    "    25       500      2850723   5701.4     99.9          grid = evolve(grid, 0.1)\n",
    "    26         1            4      4.0      0.0      return time.time() - start\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```> perf stat -e cycles,stalled-cycles-frontend,stalled-cycles-backend,instructions,\\\n",
    "cache-references,cache-misses,branches,branch-misses,task-clock,faults,\\\n",
    "minor-faults,cs,migrations -r 3 python diffusion_numpy_naive.py\n",
    "\n",
    "\n",
    " Performance counter stats for 'python diffusion_numpy_naive.py' (3 runs):\n",
    "\n",
    "    11,826,392,686      cycles                    #    3.595 GHz                      ( +-  3.90% )\n",
    "   <not supported>      stalled-cycles-frontend\n",
    "   <not supported>      stalled-cycles-backend\n",
    "    11,929,431,699      instructions              #    1.01  insns per cycle          ( +-  1.53% )\n",
    "       929,662,837      cache-references          #  282.568 M/sec                    ( +-  1.24% )\n",
    "       389,113,368      cache-misses              #   41.855 % of all cache refs      ( +-  3.40% )\n",
    "     2,449,998,393      branches                  #  744.670 M/sec                    ( +-  1.06% )\n",
    "         3,018,605      branch-misses             #    0.12% of all branches          ( +- 11.52% )\n",
    "       3290.047586      task-clock (msec)         #    1.055 CPUs utilized            ( +-  4.18% )\n",
    "           750,879      faults                    #    0.228 M/sec                    ( +-  0.00% )\n",
    "           750,863      minor-faults              #    0.228 M/sec                    ( +-  0.00% )\n",
    "            64,034      cs                        #    0.019 M/sec                    ( +- 99.70% )\n",
    "                 8      migrations                #    0.003 K/sec                    ( +- 42.33% )\n",
    "\n",
    "       3.119952520 seconds time elapsed                                          ( +-  5.83% )```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "140022980790512"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# In-place operations reducing memory allocations\n",
    "import numpy as np\n",
    "array1 = np.random.random((10,10))\n",
    "array2 = np.random.random((10, 10))\n",
    "id(array1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "140022980790512"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "array1 += array2\n",
    "id(array1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "140022980789152"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "array1 = array1 + array2\n",
    "id(array1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The slowest run took 15.87 times longer than the fastest. This could mean that an intermediate result is being cached.\n",
      "100000 loops, best of 3: 2.6 µs per loop\n"
     ]
    }
   ],
   "source": [
    "%timeit array1, array2 = np.random.random((10,10)), np.random.random((10,10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The slowest run took 29.73 times longer than the fastest. This could mean that an intermediate result is being cached.\n",
      "100000 loops, best of 3: 2.62 µs per loop\n"
     ]
    }
   ],
   "source": [
    "%timeit array1, array2 = np.random.random((10,10)), np.random.random((10,10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Numpy Reducing Memory\n",
    "from diffusion_numpy_memory import run_experiment\n",
    "%lprun -f run_experiment run_experiment(500)\n",
    "\n",
    "'''\n",
    "Total time: 1.77353 s\n",
    "File: /home/luno/Workspace/high_performance_python/diffusion_numpy_memory.py\n",
    "Function: run_experiment at line 22\n",
    "\n",
    "Line #      Hits         Time  Per Hit   % Time  Line Contents\n",
    "==============================================================\n",
    "    22                                           def run_experiment(num_iterations):\n",
    "    23         1           69     69.0      0.0      scratch = np.zeros(grid_shape)\n",
    "    24         1          140    140.0      0.0      grid = np.zeros(grid_shape)\n",
    "    25                                           \n",
    "    26         1           11     11.0      0.0      block_low = int(grid_shape[0] * .4)\n",
    "    27         1            3      3.0      0.0      block_high = int(grid_shape[0] * .5)\n",
    "    28         1          194    194.0      0.0      grid[block_low:block_high, block_low:block_high] = 0.005\n",
    "    29                                           \n",
    "    30         1            6      6.0      0.0      start = time.time()\n",
    "    31       501          375      0.7      0.0      for i in range(num_iterations):\n",
    "    32       500      1771810   3543.6     99.9          evolve(grid, 0.1, scratch)\n",
    "    33       500          914      1.8      0.1          grid, scratch = scratch, grid\n",
    "    34         1            3      3.0      0.0      return time.time() - start\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Numpy Reducing Memory - More performant, but much less readable\n",
    "from diffusion_numpy_memory2 import run_experiment\n",
    "%lprun -f run_experiment run_experiment(500)\n",
    "\n",
    "'''\n",
    "Total time: 0.870182 s\n",
    "File: /home/luno/Workspace/high_performance_python/diffusion_numpy_memory2.py\n",
    "Function: run_experiment at line 37\n",
    "\n",
    "Line #      Hits         Time  Per Hit   % Time  Line Contents\n",
    "==============================================================\n",
    "    37                                           def run_experiment(num_iterations):\n",
    "    38         1           96     96.0      0.0      scratch = zeros(grid_shape)\n",
    "    39         1          166    166.0      0.0      grid = zeros(grid_shape)\n",
    "    40                                           \n",
    "    41         1           10     10.0      0.0      block_low = int(grid_shape[0] * .4)\n",
    "    42         1            4      4.0      0.0      block_high = int(grid_shape[0] * .5)\n",
    "    43         1          232    232.0      0.0      grid[block_low:block_high, block_low:block_high] = 0.005\n",
    "    44                                           \n",
    "    45         1            9      9.0      0.0      start = time.time()\n",
    "    46       501          335      0.7      0.0      for i in range(num_iterations):\n",
    "    47       500       868637   1737.3     99.8          evolve(grid, 0.1, scratch)\n",
    "    48       500          689      1.4      0.1          grid, scratch = scratch, grid\n",
    "    49         1            4      4.0      0.0      return time.time() - start\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`numexpr`\n",
    "- take an entire vector expression and compile it to optimized code (less cache misses and temporary space used)\n",
    "- utilize multiple CPU cores and specialized instructions for Intel chips\n",
    "- rewrite the expressions as strings with referecnes to local variables.\n",
    "- Use the various CPU caches that have the correct data in order to minimize cache misses."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# The number of grid elemetns we can store in total is 20,480 KB / 64 bit = 2,560,000\n",
    "# for 20,480 KB cache (Intel Xeon ES-2680)\n",
    "# Since we have two grids, this number is split between two objects ( 2,560,000 / 2 = 1,280,000)\n",
    "# All in all, array of size 1,131 x 1,131 would fill up the cache\n",
    "#   sqrt(20480KB / 64 bit /2 ) = 1131\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from numexpr import evaluate\n",
    "def evolve(grid, dt, next_grid, D=1):\n",
    "    laplacian(grid, next_grid)\n",
    "    evaluate(\"next_grid*D*dt+grid\", out=next_grid)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "> perf stat -e cycles,stalled-cycles-frontend,stalled-cycles-backend,instructions,\\\n",
    "cache-references,cache-misses,branches,branch-misses,task-clock,faults,\\\n",
    "minor-faults,cs,migrations -r 3 python diffusion_numpy_memory2_numexpr.py\n",
    "\n",
    " Performance counter stats for 'python diffusion_numpy_memory2_numexpr.py' (3 runs):\n",
    "\n",
    "     5,119,811,553      cycles                    #    3.464 GHz                      ( +-  4.98% )\n",
    "   <not supported>      stalled-cycles-frontend\n",
    "   <not supported>      stalled-cycles-backend\n",
    "     6,102,912,408      instructions              #    1.19  insns per cycle          ( +-  4.33% )\n",
    "       603,142,928      cache-references          #  408.125 M/sec                    ( +-  0.45% )\n",
    "        57,237,731      cache-misses              #    9.490 % of all cache refs      ( +-  4.93% )\n",
    "       677,596,702      branches                  #  458.505 M/sec                    ( +-  7.76% )\n",
    "         4,615,015      branch-misses             #    0.68% of all branches          ( +-  1.00% )\n",
    "       1477.838589      task-clock (msec)         #    1.308 CPUs utilized            ( +-  6.90% )\n",
    "             9,216      faults                    #    0.006 M/sec                    ( +-  0.11% )\n",
    "             9,200      minor-faults              #    0.006 M/sec                    ( +-  0.06% )\n",
    "             4,426      cs                        #    0.003 M/sec                    ( +-  2.77% )\n",
    "             1,687      migrations                #    0.001 M/sec                    ( +-  0.96% )\n",
    "\n",
    "       1.129800061 seconds time elapsed                                          ( +-  7.59% )\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# A little bit diferent result with textbook, scipy's laplacin code shows \n",
    "# higher insns per cycle count and the higher number of `branches` "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Less `page-faults`, but more `\n",
    "```\n",
    "perf stat -e cycles,stalled-cycles-frontend,stalled-cycles-backend,instructions,\\\n",
    "cache-references,cache-misses,branches,branch-misses,task-clock,faults,\\\n",
    "minor-faults,cs,migrations -r 3 python diffusion_scipy.py\n",
    "\n",
    " Performance counter stats for 'python diffusion_scipy.py' (3 runs):\n",
    "\n",
    "     8,387,889,741      cycles                    #    3.594 GHz                      ( +-  0.81% )\n",
    "   <not supported>      stalled-cycles-frontend\n",
    "   <not supported>      stalled-cycles-backend\n",
    "    11,150,656,157      instructions              #    1.33  insns per cycle          ( +-  0.14% )\n",
    "     1,055,765,516      cache-references          #  452.324 M/sec                    ( +-  0.24% )\n",
    "       134,965,757      cache-misses              #   12.784 % of all cache refs      ( +-  1.19% )\n",
    "     1,871,308,726      branches                  #  801.729 M/sec                    ( +-  0.16% )\n",
    "         3,412,571      branch-misses             #    0.18% of all branches          ( +-  0.18% )\n",
    "       2334.091526      task-clock (msec)         #    1.083 CPUs utilized            ( +-  0.06% )\n",
    "             7,261      faults                    #    0.003 M/sec                    ( +-  0.18% )\n",
    "             7,250      minor-faults              #    0.003 M/sec                    ( +-  0.02% )\n",
    "               416      cs                        #    0.178 K/sec                    ( +- 14.99% )\n",
    "                 5      migrations                #    0.002 K/sec                    ( +- 25.75% )\n",
    "\n",
    "       2.154428789 seconds time elapsed                                          ( +-  0.40% )\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Wrap Up\n",
    "- numpy + memory + laplacian + numexpr (best)\n",
    "- numpy + memory + laplacian\n",
    "- numpy + memory\n",
    "- numpy + memory + scipy\n",
    "- numpy\n",
    "- Python + memory\n",
    "- Python (worst)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Additional Links\n",
    "- [A guide to analyzing Python performance](https://www.huyng.com/posts/python-performance-analysis)\n",
    "- [Timing and Profiling in IPython](http://pynash.org/2013/03/06/timing-and-profiling/)\n",
    "- [profile, cProfile, and pstats – Performance analysis of Python programs.](https://pymotw.com/2/profile/)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
